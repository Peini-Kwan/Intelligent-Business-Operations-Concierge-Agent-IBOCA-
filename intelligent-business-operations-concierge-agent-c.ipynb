{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Intelligent Business Operations Concierge Agent (IBOCA)\n\nThis project combines **customer support automation** with **workflow improvement** and **data analysis** into a single, cohesive multi-agent system.\n\nA **Business Operation Concierge** will be created. This single-track agent will act as an intelligent front door for internal business operations, triaging requests and orchestrating specialized sub-agents.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from google.adk.agents import Agent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import google_search\nfrom google.genai import types\n\nprint(\"âœ… ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T09:43:32.858295Z","iopub.execute_input":"2025-12-02T09:43:32.858474Z","iopub.status.idle":"2025-12-02T09:44:16.519531Z","shell.execute_reply.started":"2025-12-02T09:43:32.858456Z","shell.execute_reply":"2025-12-02T09:44:16.518553Z"}},"outputs":[{"name":"stdout","text":"âœ… ADK components imported successfully.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"root_agent = Agent(\n    name=\"helpful_assistant\",\n    model=\"gemini-2.5-flash-lite\",\n    description=\"A simple agent that can answer general questions.\",\n    instruction=\"You are a helpful assistant. Use Google Search for current info or if unsure.\",\n    tools=[google_search],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T09:44:16.521396Z","iopub.execute_input":"2025-12-02T09:44:16.522276Z","iopub.status.idle":"2025-12-02T09:44:16.527989Z","shell.execute_reply.started":"2025-12-02T09:44:16.522253Z","shell.execute_reply":"2025-12-02T09:44:16.526967Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"âœ… Setup complete (Google AI Studio).\")\nexcept Exception as e:\n    print(f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T09:44:16.534667Z","iopub.execute_input":"2025-12-02T09:44:16.535021Z","iopub.status.idle":"2025-12-02T09:44:16.676361Z","shell.execute_reply.started":"2025-12-02T09:44:16.534991Z","shell.execute_reply":"2025-12-02T09:44:16.675477Z"}},"outputs":[{"name":"stdout","text":"âœ… Setup complete (Google AI Studio).\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Display folder structure\nprint(\"Project Structure:\")\nprint(\"\"\"\nbusiness-ops-agent/\nâ”œâ”€â”€ agents/\nâ”‚   â”œâ”€â”€ orchestrator.py\nâ”‚   â”œâ”€â”€ support_agent.py\nâ”‚   â”œâ”€â”€ workflow_agent.py\nâ”‚   â””â”€â”€ data_agent.py\nâ”œâ”€â”€ tools/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ hr_tools.py\nâ”‚   â”œâ”€â”€ it_tools.py\nâ”‚   â”œâ”€â”€ data_tools.py\nâ”‚   â””â”€â”€ email_tools.py\nâ”œâ”€â”€ memory/\nâ”‚   â”œâ”€â”€ session_manager.py\nâ”‚   â””â”€â”€ memory_bank.py\nâ”œâ”€â”€ evaluation/\nâ”‚   â””â”€â”€ test_suite.py\nâ”œâ”€â”€ app.py\nâ”œâ”€â”€ requirements.txt\nâ”œâ”€â”€ Dockerfile\nâ””â”€â”€ README.md\n\"\"\")                  # Documentation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:26:55.634730Z","iopub.execute_input":"2025-12-01T17:26:55.635041Z","iopub.status.idle":"2025-12-01T17:26:55.640863Z","shell.execute_reply.started":"2025-12-01T17:26:55.635017Z","shell.execute_reply":"2025-12-01T17:26:55.639887Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1. Main Application with Multi-Agent System (app.py)","metadata":{}},{"cell_type":"code","source":"# Cell 1: Install all dependencies\n!pip install -q langchain langchain-community langchain-openai google-search-results fastapi uvicorn pandas openai\n\nprint(\"âœ… All dependencies installed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:30:33.097463Z","iopub.execute_input":"2025-12-01T17:30:33.097813Z","iopub.status.idle":"2025-12-01T17:30:46.711443Z","shell.execute_reply.started":"2025-12-01T17:30:33.097787Z","shell.execute_reply":"2025-12-01T17:30:46.710368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 1: CREATE ALL FILES AND FOLDERS\n# ============================================\nimport os\n\n# Create directories\ndirectories = [\"agents\", \"tools\", \"memory\", \"evaluation\"]\nfor dir_name in directories:\n    os.makedirs(dir_name, exist_ok=True)\n    print(f\"ðŸ“ Created folder: {dir_name}/\")\n\n# Create __init__.py files (makes them importable as modules)\nfor dir_name in directories:\n    init_file = os.path.join(dir_name, \"__init__.py\")\n    with open(init_file, \"w\") as f:\n        f.write('\"\"\"Package initialization\"\"\"\\n')\n    print(f\"ðŸ“„ Created: {init_file}\")\n\nprint(\"\\nâœ… All folders created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:31:52.623485Z","iopub.execute_input":"2025-12-01T17:31:52.624175Z","iopub.status.idle":"2025-12-01T17:31:52.631257Z","shell.execute_reply.started":"2025-12-01T17:31:52.624144Z","shell.execute_reply":"2025-12-01T17:31:52.630376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# COMPLETE SETUP CELL - RUN THIS FIRST!\n# ============================================\nimport os\nimport sys\nimport shutil\n\nprint(\"ðŸ§¹ Cleaning up old files...\")\n# Remove old folders if they exist\nfor folder in [\"agents\", \"tools\", \"memory\", \"evaluation\"]:\n    if os.path.exists(folder):\n        shutil.rmtree(folder)\n        print(f\"  Removed: {folder}/\")\n\nprint(\"\\nðŸ“ Creating new folder structure...\")\n# Create fresh folders\nfolders = [\"agents\", \"tools\", \"memory\", \"evaluation\"]\nfor folder in folders:\n    os.makedirs(folder, exist_ok=True)\n    # Create __init__.py to make it a proper Python package\n    with open(os.path.join(folder, \"__init__.py\"), \"w\") as f:\n        f.write('\"\"\"Package initialization\"\"\"\\n')\n    print(f\"  Created: {folder}/\")\n\nprint(\"\\nðŸ“„ Creating Python files...\")\n\n# 1. Create agents/orchestrator.py\norchestrator_code = '''\"\"\"\nOrchestrator Agent\n\"\"\"\nimport json\n\nclass OrchestratorAgent:\n    \"\"\"Main orchestrator implementing A2A protocol patterns\"\"\"\n    \n    def __init__(self, llm=None, tools=None, support_agent=None, \n                 workflow_agent=None, data_agent=None, memory_bank=None):\n        self.llm = llm\n        self.tools = tools or []\n        self.support_agent = support_agent\n        self.workflow_agent = workflow_agent\n        self.data_agent = data_agent\n        self.memory_bank = memory_bank\n        \n    async def coordinate_agents(self, task: str):\n        \"\"\"Coordinate between multiple agents (A2A Protocol)\"\"\"\n        return {\n            \"status\": \"success\",\n            \"task\": task,\n            \"agents_involved\": [\"support\", \"workflow\", \"data\"],\n            \"result\": f\"Processed: {task} using multiple agents\"\n        }\n    \n    async def use_tools(self, query: str, tool_types=None):\n        \"\"\"Use available tools based on query\"\"\"\n        if tool_types:\n            return f\"Using tools of type {tool_types} for query: {query}\"\n        return f\"Using all available tools for query: {query}\"\n\n# For testing\nif __name__ == \"__main__\":\n    agent = OrchestratorAgent()\n    print(\"OrchestratorAgent created successfully!\")\n'''\n\nwith open(\"agents/orchestrator.py\", \"w\") as f:\n    f.write(orchestrator_code)\nprint(\"  âœ… agents/orchestrator.py\")\n\n# 2. Create agents/support_agent.py\nsupport_agent_code = '''\"\"\"\nSupport Specialist Agent\n\"\"\"\nclass SupportSpecialist:\n    \"\"\"Support specialist agent for handling inquiries\"\"\"\n    \n    def __init__(self, llm=None):\n        self.llm = llm\n    \n    async def answer_question(self, question: str) -> str:\n        \"\"\"Answer support questions\"\"\"\n        return f\"I can help with: {question}. Based on our knowledge base, the solution is...\"\n    \n    async def check_knowledge_base(self, query: str) -> str:\n        \"\"\"Check knowledge base for answers\"\"\"\n        answers = {\n            \"password reset\": \"Go to portal.example.com/password-reset\",\n            \"vpn issues\": \"Try restarting the VPN client or contact IT\",\n            \"software installation\": \"Download from company portal or request admin rights\"\n        }\n        for key in answers:\n            if key in query.lower():\n                return answers[key]\n        return \"I couldn't find a specific answer. Let me connect you with a human agent.\"\n\n# For testing\nif __name__ == \"__main__\":\n    agent = SupportSpecialist()\n    print(\"SupportSpecialist created successfully!\")\n'''\n\nwith open(\"agents/support_agent.py\", \"w\") as f:\n    f.write(support_agent_code)\nprint(\"  âœ… agents/support_agent.py\")\n\n# 3. Create agents/workflow_agent.py\nworkflow_agent_code = '''\"\"\"\nWorkflow Automation Agent\n\"\"\"\nclass WorkflowAgent:\n    \"\"\"Workflow automation agent for sequential processes\"\"\"\n    \n    def __init__(self, llm=None):\n        self.llm = llm\n    \n    async def execute_workflow(self, workflow_name: str) -> str:\n        \"\"\"Execute a workflow sequentially\"\"\"\n        steps = {\n            \"leave_request\": [\"Submit form\", \"Manager approval\", \"HR processing\", \"Confirmation\"],\n            \"expense_report\": [\"Collect receipts\", \"Fill form\", \"Submit\", \"Finance review\", \"Reimbursement\"],\n            \"onboarding\": [\"Paperwork\", \"IT setup\", \"Training\", \"Team introduction\"]\n        }\n        \n        if workflow_name in steps:\n            workflow_steps = steps[workflow_name]\n            result = f\"Executing '{workflow_name}' workflow:\\\\n\"\n            for i, step in enumerate(workflow_steps, 1):\n                result += f\"  Step {i}: {step} âœ“\\\\n\"\n            return result + \"âœ… Workflow completed!\"\n        return f\"Workflow '{workflow_name}' not found.\"\n\n# For testing\nif __name__ == \"__main__\":\n    agent = WorkflowAgent()\n    print(\"WorkflowAgent created successfully!\")\n'''\n\nwith open(\"agents/workflow_agent.py\", \"w\") as f:\n    f.write(workflow_agent_code)\nprint(\"  âœ… agents/workflow_agent.py\")\n\n# 4. Create agents/data_agent.py\ndata_agent_code = '''\"\"\"\nData Analysis Agent\n\"\"\"\nimport asyncio\n\nclass DataAnalysisAgent:\n    \"\"\"Data analysis agent for parallel processing\"\"\"\n    \n    def __init__(self, llm=None):\n        self.llm = llm\n    \n    async def analyze_trends(self, period=\"monthly\") -> str:\n        \"\"\"Analyze data trends\"\"\"\n        await asyncio.sleep(0.1)  # Simulate processing\n        return f\"{period.capitalize()} trends: Support tickets â†“15%, Resolution time â†“20%, Satisfaction â†‘10%\"\n    \n    async def generate_report(self, report_type: str) -> str:\n        \"\"\"Generate a report\"\"\"\n        await asyncio.sleep(0.1)\n        reports = {\n            \"weekly\": \"Weekly Report: 150 tickets, 85% resolution rate\",\n            \"monthly\": \"Monthly Report: 600 tickets, Avg response: 2.1h\",\n            \"quarterly\": \"Q1 Report: 2400 tickets, CSAT: 4.5/5.0\"\n        }\n        return reports.get(report_type, f\"Standard report for {report_type}\")\n    \n    async def calculate_metrics(self) -> str:\n        \"\"\"Calculate business metrics\"\"\"\n        await asyncio.sleep(0.1)\n        return \"Current Metrics: Active tickets: 42, SLA compliance: 92%, Agent utilization: 78%\"\n\n# For testing\nif __name__ == \"__main__\":\n    agent = DataAnalysisAgent()\n    print(\"DataAnalysisAgent created successfully!\")\n'''\n\nwith open(\"agents/data_agent.py\", \"w\") as f:\n    f.write(data_agent_code)\nprint(\"  âœ… agents/data_agent.py\")\n\n# 5. Create tools/hr_tools.py\nhr_tools_code = '''\"\"\"\nHR Tools Module\n\"\"\"\nclass HRToolkit:\n    \"\"\"Collection of HR-related tools\"\"\"\n    \n    def get_tools(self):\n        return [LeaveBalanceTool(), PolicyLookupTool(), EmployeeDirectoryTool()]\n\nclass LeaveBalanceTool:\n    \"\"\"Custom tool for checking leave balance\"\"\"\n    \n    name = \"check_leave_balance\"\n    description = \"Check an employee's remaining leave balance\"\n    tool_type = \"hr_tools\"\n    \n    def run(self, employee_id: str, leave_type: str = None) -> str:\n        \"\"\"Execute the tool\"\"\"\n        balances = {\n            \"EMP001\": {\"vacation\": 15, \"sick\": 10, \"personal\": 5},\n            \"EMP002\": {\"vacation\": 20, \"sick\": 8, \"personal\": 3},\n            \"EMP003\": {\"vacation\": 12, \"sick\": 12, \"personal\": 8}\n        }\n        \n        if employee_id not in balances:\n            return f\"Employee {employee_id} not found\"\n        \n        if leave_type:\n            if leave_type in balances[employee_id]:\n                balance = balances[employee_id][leave_type]\n                return f\"Employee {employee_id} has {balance} days of {leave_type} leave\"\n            return f\"Leave type '{leave_type}' not found\"\n        \n        # Return all balances\n        return f\"Leave balances for {employee_id}: {balances[employee_id]}\"\n\nclass PolicyLookupTool:\n    \"\"\"Tool to look up HR policies\"\"\"\n    \n    name = \"lookup_policy\"\n    description = \"Look up HR policies by topic\"\n    tool_type = \"hr_tools\"\n    \n    def run(self, policy_topic: str) -> str:\n        policies = {\n            \"remote_work\": \"Employees may work remotely 3 days/week with manager approval.\",\n            \"leave_request\": \"Submit leave requests 2 weeks in advance via HR portal.\",\n            \"expenses\": \"Expense reports must be submitted within 30 days with receipts.\",\n            \"overtime\": \"Overtime requires pre-approval and is paid at 1.5x rate.\"\n        }\n        return policies.get(policy_topic.lower(), f\"No policy found for: {policy_topic}\")\n\nclass EmployeeDirectoryTool:\n    \"\"\"Employee directory tool\"\"\"\n    \n    name = \"employee_directory\"\n    description = \"Look up employee information\"\n    tool_type = \"hr_tools\"\n    \n    def run(self, employee_id: str = None, department: str = None) -> str:\n        employees = [\n            {\"id\": \"EMP001\", \"name\": \"John Doe\", \"department\": \"Engineering\", \"role\": \"Developer\"},\n            {\"id\": \"EMP002\", \"name\": \"Jane Smith\", \"department\": \"Marketing\", \"role\": \"Manager\"},\n            {\"id\": \"EMP003\", \"name\": \"Bob Johnson\", \"department\": \"HR\", \"role\": \"Specialist\"}\n        ]\n        \n        if employee_id:\n            for emp in employees:\n                if emp[\"id\"] == employee_id:\n                    return f\"Employee: {emp['name']}, Dept: {emp['department']}, Role: {emp['role']}\"\n            return f\"Employee {employee_id} not found\"\n        \n        if department:\n            dept_employees = [e for e in employees if e[\"department\"].lower() == department.lower()]\n            if dept_employees:\n                return f\"Employees in {department}: {[e['name'] for e in dept_employees]}\"\n            return f\"No employees found in {department}\"\n        \n        return f\"Total employees: {len(employees)}\"\n\n# For testing\nif __name__ == \"__main__\":\n    toolkit = HRToolkit()\n    print(f\"HR Toolkit created with {len(toolkit.get_tools())} tools\")\n'''\n\nwith open(\"tools/hr_tools.py\", \"w\") as f:\n    f.write(hr_tools_code)\nprint(\"  âœ… tools/hr_tools.py\")\n\n# 6. Create memory/session_manager.py\nsession_manager_code = '''\"\"\"\nSession Manager\n\"\"\"\nfrom datetime import datetime\n\nclass SessionManager:\n    \"\"\"Manage user sessions\"\"\"\n    \n    def __init__(self):\n        self.sessions = {}\n    \n    def create_session(self, user_id: str) -> str:\n        \"\"\"Create a new session\"\"\"\n        session_id = f\"{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        self.sessions[session_id] = {\n            \"user_id\": user_id,\n            \"created_at\": datetime.now(),\n            \"data\": {},\n            \"history\": []\n        }\n        return session_id\n    \n    def update_session(self, session_id: str, data: dict) -> bool:\n        \"\"\"Update session data\"\"\"\n        if session_id in self.sessions:\n            self.sessions[session_id][\"data\"].update(data)\n            self.sessions[session_id][\"history\"].append({\n                \"timestamp\": datetime.now(),\n                \"action\": \"update\",\n                \"data\": data\n            })\n            return True\n        return False\n    \n    def get_session(self, session_id: str) -> dict:\n        \"\"\"Get session data\"\"\"\n        return self.sessions.get(session_id, {})\n    \n    def end_session(self, session_id: str) -> bool:\n        \"\"\"End a session\"\"\"\n        if session_id in self.sessions:\n            del self.sessions[session_id]\n            return True\n        return False\n\n# For testing\nif __name__ == \"__main__\":\n    manager = SessionManager()\n    session_id = manager.create_session(\"EMP001\")\n    print(f\"Session created: {session_id}\")\n'''\n\nwith open(\"memory/session_manager.py\", \"w\") as f:\n    f.write(session_manager_code)\nprint(\"  âœ… memory/session_manager.py\")\n\n# 7. Create memory/memory_bank.py\nmemory_bank_code = '''\"\"\"\nMemory Bank for long-term storage\n\"\"\"\nfrom datetime import datetime, timedelta\nfrom collections import defaultdict\n\nclass MemoryBank:\n    \"\"\"Long-term memory storage with context compaction\"\"\"\n    \n    def __init__(self, max_entries_per_user: int = 50):\n        self.memory_store = defaultdict(list)\n        self.max_entries = max_entries_per_user\n    \n    def store(self, user_id: str, key: str, value: str, metadata: dict = None) -> str:\n        \"\"\"Store information in long-term memory\"\"\"\n        entry = {\n            \"id\": f\"{user_id}_{key}_{datetime.now().timestamp()}\",\n            \"key\": key,\n            \"value\": value,\n            \"timestamp\": datetime.now(),\n            \"metadata\": metadata or {},\n            \"access_count\": 0\n        }\n        \n        self.memory_store[user_id].append(entry)\n        \n        # Apply context compaction if needed\n        if len(self.memory_store[user_id]) > self.max_entries:\n            self._compact_context(user_id)\n        \n        return entry[\"id\"]\n    \n    def recall(self, user_id: str, key: str = None, limit: int = 5) -> list:\n        \"\"\"Recall information from memory\"\"\"\n        if user_id not in self.memory_store:\n            return []\n        \n        memories = self.memory_store[user_id]\n        \n        # Filter by key if specified\n        if key:\n            relevant = [m for m in memories if key in m[\"key\"]]\n        else:\n            relevant = memories\n        \n        # Sort by recency\n        relevant.sort(key=lambda x: x[\"timestamp\"], reverse=True)\n        \n        # Update access count\n        for memory in relevant[:limit]:\n            memory[\"access_count\"] += 1\n        \n        return [\n            {\n                \"key\": m[\"key\"],\n                \"value\": m[\"value\"],\n                \"age\": (datetime.now() - m[\"timestamp\"]).days,\n                \"accessed\": m[\"access_count\"]\n            }\n            for m in relevant[:limit]\n        ]\n    \n    def _compact_context(self, user_id: str):\n        \"\"\"Context compaction: remove least accessed memories\"\"\"\n        memories = self.memory_store[user_id]\n        \n        # Sort by access count (least accessed first)\n        memories.sort(key=lambda x: x[\"access_count\"])\n        \n        # Keep only the most recent/accessed memories\n        keep_count = self.max_entries // 2\n        self.memory_store[user_id] = memories[-keep_count:] if len(memories) > keep_count else memories\n    \n    def get_stats(self, user_id: str) -> dict:\n        \"\"\"Get memory statistics for a user\"\"\"\n        if user_id not in self.memory_store:\n            return {\"total_memories\": 0, \"last_access\": None}\n        \n        memories = self.memory_store[user_id]\n        if not memories:\n            return {\"total_memories\": 0, \"last_access\": None}\n        \n        return {\n            \"total_memories\": len(memories),\n            \"last_access\": max(m[\"timestamp\"] for m in memories).isoformat(),\n            \"most_accessed\": max(memories, key=lambda x: x[\"access_count\"])[\"key\"]\n        }\n\n# For testing\nif __name__ == \"__main__\":\n    memory = MemoryBank()\n    memory.store(\"EMP001\", \"hr_question\", \"Asked about vacation policy\")\n    print(\"MemoryBank created successfully!\")\n'''\n\nwith open(\"memory/memory_bank.py\", \"w\") as f:\n    f.write(memory_bank_code)\nprint(\"  âœ… memory/memory_bank.py\")\n\n# 8. Create evaluation/test_suite.py\ntest_suite_code = '''\"\"\"\nAgent Evaluation Suite\n\"\"\"\nfrom datetime import datetime\n\nclass AgentEvaluator:\n    \"\"\"Evaluate agent performance\"\"\"\n    \n    def __init__(self, agent=None):\n        self.agent = agent\n        self.test_cases = [\n            {\"input\": \"What's my vacation balance?\", \"expected\": \"hr_inquiry\", \"category\": \"HR\"},\n            {\"input\": \"My laptop won't turn on\", \"expected\": \"it_support\", \"category\": \"IT\"},\n            {\"input\": \"Show last month's metrics\", \"expected\": \"data_analysis\", \"category\": \"Data\"},\n            {\"input\": \"How do I submit expenses?\", \"expected\": \"workflow\", \"category\": \"Workflow\"}\n        ]\n    \n    async def evaluate_intent_classification(self) -> dict:\n        \"\"\"Evaluate intent classification accuracy\"\"\"\n        # Simulate evaluation\n        correct = 3\n        total = len(self.test_cases)\n        \n        return {\n            \"accuracy\": correct / total,\n            \"correct_count\": correct,\n            \"total_tests\": total,\n            \"details\": [{\"test\": tc[\"input\"], \"status\": \"PASS\" if i < 3 else \"FAIL\"} \n                       for i, tc in enumerate(self.test_cases)]\n        }\n    \n    async def evaluate_tool_selection(self) -> dict:\n        \"\"\"Evaluate tool selection accuracy\"\"\"\n        return {\n            \"tool_selection_accuracy\": 0.85,\n            \"correct_selections\": 17,\n            \"total_tests\": 20,\n            \"details\": \"Tools correctly selected in 85% of cases\"\n        }\n    \n    async def run_complete_evaluation(self) -> dict:\n        \"\"\"Run all evaluations\"\"\"\n        intent_results = await self.evaluate_intent_classification()\n        tool_results = await self.evaluate_tool_selection()\n        \n        overall_score = (intent_results[\"accuracy\"] * 0.6 + \n                        tool_results[\"tool_selection_accuracy\"] * 0.4)\n        \n        return {\n            \"overall_score\": overall_score,\n            \"intent_classification\": intent_results,\n            \"tool_selection\": tool_results,\n            \"passing_threshold\": 0.7,\n            \"passed\": overall_score >= 0.7,\n            \"evaluation_date\": datetime.now().isoformat(),\n            \"agent_version\": \"1.0.0\"\n        }\n\n# For testing\nif __name__ == \"__main__\":\n    evaluator = AgentEvaluator()\n    print(\"AgentEvaluator created successfully!\")\n'''\n\nwith open(\"evaluation/test_suite.py\", \"w\") as f:\n    f.write(test_suite_code)\nprint(\"  âœ… evaluation/test_suite.py\")\n\n# Create requirements.txt\nrequirements = '''langchain>=0.1.0\nlangchain-community>=0.0.10\nlangchain-openai>=0.0.2\nopenai>=1.3.0\ngoogle-search-results>=2.4.2\nfastapi>=0.104.1\nuvicorn>=0.24.0\npandas>=2.1.3\nnumpy>=1.24.3\nrequests>=2.31.0\npython-dotenv>=1.0.0\n'''\n\nwith open(\"requirements.txt\", \"w\") as f:\n    f.write(requirements)\nprint(\"  âœ… requirements.txt\")\n\n# Create app.py stub\napp_code = '''\"\"\"\nMain Application - Business Operations Concierge Agent\n\"\"\"\nprint(\"ðŸš€ Business Operations Concierge Agent\")\nprint(\"âœ… All modules are ready to import!\")\n'''\n\nwith open(\"app.py\", \"w\") as f:\n    f.write(app_code)\nprint(\"  âœ… app.py\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"ðŸŽ‰ SETUP COMPLETE!\")\nprint(\"=\"*50)\nprint(\"\\nNow you can safely run:\")\nprint(\"from agents.orchestrator import OrchestratorAgent\")\nprint(\"from agents.support_agent import SupportSpecialist\")\nprint(\"from agents.workflow_agent import WorkflowAgent\")\nprint(\"from agents.data_agent import DataAnalysisAgent\")\nprint(\"from tools.hr_tools import HRToolkit\")\nprint(\"from memory.session_manager import SessionManager\")\nprint(\"from memory.memory_bank import MemoryBank\")\nprint(\"from evaluation.test_suite import AgentEvaluator\")\nprint(\"\\nâœ… All imports will work!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:42:35.084713Z","iopub.execute_input":"2025-12-01T17:42:35.085325Z","iopub.status.idle":"2025-12-01T17:42:35.110873Z","shell.execute_reply.started":"2025-12-01T17:42:35.085302Z","shell.execute_reply":"2025-12-01T17:42:35.110078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CREATE tools/it_tools.py\n# ============================================\nimport os\n\nit_tools_code = '''\"\"\"\nIT Tools Module\n\"\"\"\nimport random\nfrom datetime import datetime\n\nclass ITToolkit:\n    \"\"\"Collection of IT-related tools\"\"\"\n    \n    def get_tools(self):\n        return [\n            CreateTicketTool(),\n            SystemStatusTool(),\n            PasswordResetTool(),\n            SoftwareInstallTool()\n        ]\n\nclass CreateTicketTool:\n    \"\"\"Tool for creating IT support tickets\"\"\"\n    \n    name = \"create_ticket\"\n    description = \"Create an IT support ticket\"\n    tool_type = \"it_tools\"\n    \n    def run(self, description: str, priority: str = \"medium\", category: str = None) -> dict:\n        \"\"\"Create a support ticket\"\"\"\n        ticket_id = f\"TICKET-{datetime.now().strftime('%Y%m%d')}-{random.randint(1000, 9999)}\"\n        \n        priorities = {\"low\": \"Low\", \"medium\": \"Medium\", \"high\": \"High\", \"critical\": \"Critical\"}\n        priority_display = priorities.get(priority.lower(), \"Medium\")\n        \n        categories = [\"hardware\", \"software\", \"network\", \"account\", \"other\"]\n        if category and category.lower() in categories:\n            assigned_category = category.lower()\n        else:\n            # Auto-detect category from description\n            desc_lower = description.lower()\n            if any(word in desc_lower for word in [\"laptop\", \"computer\", \"printer\", \"hardware\"]):\n                assigned_category = \"hardware\"\n            elif any(word in desc_lower for word in [\"software\", \"install\", \"update\", \"program\"]):\n                assigned_category = \"software\"\n            elif any(word in desc_lower for word in [\"wifi\", \"network\", \"internet\", \"vpn\"]):\n                assigned_category = \"network\"\n            elif any(word in desc_lower for word in [\"password\", \"login\", \"account\", \"access\"]):\n                assigned_category = \"account\"\n            else:\n                assigned_category = \"other\"\n        \n        return {\n            \"ticket_id\": ticket_id,\n            \"status\": \"created\",\n            \"description\": description,\n            \"priority\": priority_display,\n            \"category\": assigned_category,\n            \"created_at\": datetime.now().isoformat(),\n            \"estimated_resolution\": \"24-48 hours\" if priority != \"critical\" else \"4-8 hours\",\n            \"message\": f\"Ticket {ticket_id} created successfully. An IT specialist will contact you soon.\"\n        }\n\nclass SystemStatusTool:\n    \"\"\"Tool for checking system status\"\"\"\n    \n    name = \"check_system_status\"\n    description = \"Check the status of various IT systems\"\n    tool_type = \"it_tools\"\n    \n    def run(self, system: str = None) -> dict:\n        \"\"\"Check system status\"\"\"\n        systems_status = {\n            \"email\": {\"status\": \"operational\", \"uptime\": \"99.9%\", \"last_incident\": \"7 days ago\"},\n            \"vpn\": {\"status\": \"operational\", \"uptime\": \"99.5%\", \"last_incident\": \"2 days ago\"},\n            \"file_server\": {\"status\": \"degraded\", \"uptime\": \"95.2%\", \"last_incident\": \"Today 09:00\"},\n            \"website\": {\"status\": \"operational\", \"uptime\": \"99.8%\", \"last_incident\": \"14 days ago\"},\n            \"database\": {\"status\": \"operational\", \"uptime\": \"99.95%\", \"last_incident\": \"30 days ago\"}\n        }\n        \n        if system:\n            if system.lower() in systems_status:\n                return {\n                    \"system\": system,\n                    **systems_status[system.lower()],\n                    \"checked_at\": datetime.now().isoformat()\n                }\n            else:\n                return {\n                    \"error\": f\"System '{system}' not found\",\n                    \"available_systems\": list(systems_status.keys())\n                }\n        \n        # Return all systems status\n        return {\n            \"overall_status\": \"operational\",\n            \"systems\": systems_status,\n            \"summary\": f\"{len([s for s in systems_status.values() if s['status'] == 'operational'])}/{len(systems_status)} systems operational\",\n            \"checked_at\": datetime.now().isoformat()\n        }\n\nclass PasswordResetTool:\n    \"\"\"Tool for password reset operations\"\"\"\n    \n    name = \"reset_password\"\n    description = \"Reset user password or send reset link\"\n    tool_type = \"it_tools\"\n    \n    def run(self, username: str, method: str = \"email\") -> dict:\n        \"\"\"Reset password for a user\"\"\"\n        methods = {\n            \"email\": \"Password reset link sent to registered email\",\n            \"sms\": \"Password reset code sent via SMS\",\n            \"automated\": \"Password has been automatically reset. Check email for new password.\",\n            \"manual\": \"Password reset request logged. IT staff will contact you.\"\n        }\n        \n        if method not in methods:\n            method = \"email\"\n        \n        reset_id = f\"RESET-{datetime.now().strftime('%H%M%S')}-{random.randint(100, 999)}\"\n        \n        return {\n            \"reset_id\": reset_id,\n            \"username\": username,\n            \"method\": method,\n            \"status\": \"initiated\",\n            \"message\": methods[method],\n            \"instructions\": \"If you don't receive the reset within 10 minutes, contact IT support.\",\n            \"timestamp\": datetime.now().isoformat()\n        }\n\nclass SoftwareInstallTool:\n    \"\"\"Tool for software installation requests\"\"\"\n    \n    name = \"request_software_install\"\n    description = \"Request software installation or license\"\n    tool_type = \"it_tools\"\n    \n    def run(self, software_name: str, version: str = \"latest\", reason: str = None) -> dict:\n        \"\"\"Request software installation\"\"\"\n        software_catalog = {\n            \"microsoft office\": {\"license_type\": \"enterprise\", \"approval_required\": False},\n            \"adobe creative cloud\": {\"license_type\": \"subscription\", \"approval_required\": True},\n            \"visual studio code\": {\"license_type\": \"free\", \"approval_required\": False},\n            \"slack\": {\"license_type\": \"enterprise\", \"approval_required\": False},\n            \"zoom\": {\"license_type\": \"enterprise\", \"approval_required\": False},\n            \"specialized_tool\": {\"license_type\": \"individual\", \"approval_required\": True}\n        }\n        \n        software_lower = software_name.lower()\n        \n        if software_lower in software_catalog:\n            software_info = software_catalog[software_lower]\n        else:\n            software_info = {\"license_type\": \"unknown\", \"approval_required\": True}\n        \n        request_id = f\"SOFTWARE-{datetime.now().strftime('%Y%m%d')}-{random.randint(100, 999)}\"\n        \n        approval_message = \"\"\n        if software_info[\"approval_required\"]:\n            approval_message = \"This software requires manager approval. Request has been forwarded.\"\n        else:\n            approval_message = \"Software can be installed immediately. Check your email for installation link.\"\n        \n        return {\n            \"request_id\": request_id,\n            \"software\": software_name,\n            \"version\": version,\n            \"license_type\": software_info[\"license_type\"],\n            \"approval_required\": software_info[\"approval_required\"],\n            \"status\": \"submitted\",\n            \"message\": approval_message,\n            \"reason\": reason or \"Not specified\",\n            \"estimated_time\": \"24 hours\" if software_info[\"approval_required\"] else \"2 hours\",\n            \"submitted_at\": datetime.now().isoformat()\n        }\n\n# For testing\nif __name__ == \"__main__\":\n    toolkit = ITToolkit()\n    print(f\"IT Toolkit created with {len(toolkit.get_tools())} tools:\")\n    for tool in toolkit.get_tools():\n        print(f\"  - {tool.name}: {tool.description}\")\n'''\n\n# Create the tools directory if it doesn't exist\nos.makedirs(\"tools\", exist_ok=True)\n\n# Create __init__.py if it doesn't exist\nif not os.path.exists(\"tools/__init__.py\"):\n    with open(\"tools/__init__.py\", \"w\") as f:\n        f.write('\"\"\"Tools package\"\"\"')\n\n# Write the it_tools.py file\nwith open(\"tools/it_tools.py\", \"w\") as f:\n    f.write(it_tools_code)\n\nprint(\"âœ… Created: tools/it_tools.py\")\nprint(\"\\nðŸ“‹ Available IT Tools:\")\nprint(\"1. CreateTicketTool - Create IT support tickets\")\nprint(\"2. SystemStatusTool - Check system status\")\nprint(\"3. PasswordResetTool - Reset user passwords\")\nprint(\"4. SoftwareInstallTool - Request software installation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:44:12.706970Z","iopub.execute_input":"2025-12-01T17:44:12.707905Z","iopub.status.idle":"2025-12-01T17:44:12.719662Z","shell.execute_reply.started":"2025-12-01T17:44:12.707863Z","shell.execute_reply":"2025-12-01T17:44:12.718647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import asyncio\nimport threading\nfrom fastapi import FastAPI\nimport uvicorn\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef home():\n    return {\"message\": \"Business Ops Agent API Running\"}\n\n@app.get(\"/health\")\ndef health():\n    return {\"status\": \"healthy\"}\n\ndef run_server():\n    \"\"\"Run the server in a separate thread\"\"\"\n    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n    server = uvicorn.Server(config)\n    server.run()\n\n# Start server in background thread\nprint(\"ðŸš€ Starting server on http://localhost:8000\")\nprint(\"ðŸ“‹ Available endpoints:\")\nprint(\"  - GET /          - API homepage\")\nprint(\"  - GET /health    - Health check\")\nprint(\"  - POST /process  - Process requests\")\n\n# Start the server in a background thread\nserver_thread = threading.Thread(target=run_server, daemon=True)\nserver_thread.start()\n\n# Give server time to start\nimport time\ntime.sleep(2)\n\nprint(\"\\nâœ… Server is running in the background!\")\nprint(\"ðŸ’¡ To stop: Kernel â†’ Interrupt or Restart\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:46:04.839343Z","iopub.execute_input":"2025-12-01T17:46:04.839692Z","iopub.status.idle":"2025-12-01T17:46:06.848797Z","shell.execute_reply.started":"2025-12-01T17:46:04.839667Z","shell.execute_reply":"2025-12-01T17:46:06.847994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nIntelligent Business Operations Concierge Agent\nDemonstrates: Multi-agent system, Tools, Memory, Observability, Deployment\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any, List\nfrom datetime import datetime\nimport asyncio\n\n# Import agent framework (using LangChain as example)\nfrom langchain.agents import AgentExecutor, create_react_agent\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.prompts import PromptTemplate\nfrom langchain_community.tools import GoogleSearchRun\nfrom langchain_openai import ChatOpenAI\n\n# Import custom modules\nfrom agents.orchestrator import OrchestratorAgent\nfrom agents.support_agent import SupportSpecialist\nfrom agents.workflow_agent import WorkflowAgent\nfrom agents.data_agent import DataAnalysisAgent\nfrom tools.hr_tools import HRToolkit\nfrom tools.it_tools import ITToolkit\nfrom memory.session_manager import SessionManager\nfrom memory.memory_bank import MemoryBank\n\n# Configure logging for observability\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('agent_operations.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\nclass BusinessOperationsConcierge:\n    \"\"\"Main orchestrator class demonstrating multi-agent system\"\"\"\n    \n    def __init__(self, user_id: str):\n        # Initialize memory components\n        self.session_manager = SessionManager()\n        self.memory_bank = MemoryBank()\n        \n        # Create user session\n        self.session_id = self.session_manager.create_session(user_id)\n        \n        # Initialize LLM\n        self.llm = ChatOpenAI(\n            model=\"gpt-4\",\n            temperature=0.3,\n            streaming=True\n        )\n        \n        # Initialize specialist agents (parallel capability)\n        self.support_agent = SupportSpecialist(self.llm)\n        self.workflow_agent = WorkflowAgent(self.llm)\n        self.data_agent = DataAnalysisAgent(self.llm)\n        \n        # Initialize toolkits\n        self.hr_tools = HRToolkit().get_tools()\n        self.it_tools = ITToolkit().get_tools()\n        self.google_search = GoogleSearchRun()\n        \n        # Build orchestrator agent with all tools\n        all_tools = self.hr_tools + self.it_tools + [self.google_search]\n        \n        self.orchestrator = OrchestratorAgent(\n            llm=self.llm,\n            tools=all_tools,\n            support_agent=self.support_agent,\n            workflow_agent=self.workflow_agent,\n            data_agent=self.data_agent,\n            memory_bank=self.memory_bank\n        )\n        \n        logger.info(f\"Initialized BusinessOperationsConcierge for user {user_id}\")\n    \n    async def process_request(self, user_input: str) -> Dict[str, Any]:\n        \"\"\"Process user request using multi-agent system\"\"\"\n        \n        # Log the incoming request\n        logger.info(f\"Processing request: {user_input}\")\n        \n        try:\n            # Classify intent and route to appropriate agent\n            intent = await self._classify_intent(user_input)\n            logger.info(f\"Classified intent: {intent}\")\n            \n            # Update session memory\n            self.session_manager.update_session(\n                self.session_id,\n                {\"last_input\": user_input, \"intent\": intent, \"timestamp\": datetime.now()}\n            )\n            \n            # Route to appropriate agent based on intent\n            if intent == \"it_support\":\n                response = await self._handle_it_support(user_input)\n            elif intent == \"hr_inquiry\":\n                response = await self._handle_hr_inquiry(user_input)\n            elif intent == \"data_analysis\":\n                # Run data analysis in parallel with other tasks if needed\n                response = await self._handle_data_request(user_input)\n            elif intent == \"workflow\":\n                response = await self._handle_workflow(user_input)\n            else:\n                response = await self._handle_general_support(user_input)\n            \n            # Store in long-term memory if important\n            if intent in [\"hr_inquiry\", \"it_support\"]:\n                self.memory_bank.store(\n                    user_id=self.session_id,\n                    key=intent,\n                    value=user_input[:100],  # Store snippet\n                    metadata={\"timestamp\": datetime.now()}\n                )\n            \n            return {\n                \"response\": response,\n                \"intent\": intent,\n                \"session_id\": self.session_id,\n                \"timestamp\": datetime.now().isoformat()\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error processing request: {e}\", exc_info=True)\n            return {\"error\": str(e), \"session_id\": self.session_id}\n    \n    async def _classify_intent(self, user_input: str) -> str:\n        \"\"\"Classify user intent using LLM\"\"\"\n        prompt = f\"\"\"\n        Classify the following user request into one of these categories:\n        - it_support: Technical issues, password resets, software problems\n        - hr_inquiry: Leave balance, benefits, policies, payroll\n        - data_analysis: Reports, analytics, trends, metrics\n        - workflow: Process automation, approvals, form submissions\n        - general: Questions, information requests\n        \n        User request: \"{user_input}\"\n        \n        Return only the category name.\n        \"\"\"\n        \n        response = await self.llm.ainvoke(prompt)\n        return response.content.strip().lower()\n    \n    async def _handle_it_support(self, user_input: str) -> str:\n        \"\"\"Sequential agent workflow for IT support\"\"\"\n        # Step 1: Check if it's a common issue\n        common_issues = await self.support_agent.check_knowledge_base(user_input)\n        \n        if common_issues:\n            return common_issues\n        \n        # Step 2: Try to resolve with tools\n        tools_response = await self.orchestrator.use_tools(\n            user_input, \n            tool_types=[\"it_tools\"]\n        )\n        \n        # Step 3: If unresolved, create ticket\n        if \"unresolved\" in tools_response.lower():\n            ticket_id = await self.it_tools[0].create_ticket(\n                description=user_input,\n                priority=\"medium\"\n            )\n            return f\"I've created a support ticket #{ticket_id} for you.\"\n        \n        return tools_response\n    \n    async def _handle_hr_inquiry(self, user_input: str) -> str:\n        \"\"\"Handle HR inquiries with memory recall\"\"\"\n        # Check memory bank first\n        memory_result = self.memory_bank.recall(\n            user_id=self.session_id,\n            key=\"hr_inquiry\"\n        )\n        \n        # Use HR tools\n        hr_response = await self.orchestrator.use_tools(\n            user_input,\n            tool_types=[\"hr_tools\"]\n        )\n        \n        if memory_result:\n            return f\"Based on our previous conversations, I remember you asked about similar topics. {hr_response}\"\n        \n        return hr_response\n    \n    async def _handle_data_request(self, user_input: str) -> str:\n        \"\"\"Parallel data processing\"\"\"\n        # Run multiple analyses in parallel\n        tasks = [\n            self.data_agent.analyze_trends(),\n            self.data_agent.generate_report(user_input),\n            self.data_agent.calculate_metrics()\n        ]\n        \n        results = await asyncio.gather(*tasks)\n        \n        return f\"Data Analysis Complete:\\n1. Trends: {results[0]}\\n2. Report: {results[1]}\\n3. Metrics: {results[2]}\"\n    \n    async def _handle_workflow(self, user_input: str) -> str:\n        \"\"\"Sequential workflow execution\"\"\"\n        return await self.workflow_agent.execute_workflow(user_input)\n    \n    async def _handle_general_support(self, user_input: str) -> str:\n        \"\"\"General support with Google search fallback\"\"\"\n        response = await self.support_agent.answer_question(user_input)\n        \n        if \"I don't know\" in response:\n            # Use Google search tool\n            search_result = self.google_search.run(f\"{user_input} business operations\")\n            return f\"I found this information: {search_result[:200]}...\"\n        \n        return response\n\n# FastAPI deployment\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport uvicorn\n\napp = FastAPI(title=\"Business Operations Agent API\")\n\nclass UserRequest(BaseModel):\n    user_id: str\n    message: str\n\n@app.post(\"/process\")\nasync def process_request(request: UserRequest):\n    \"\"\"API endpoint for agent processing\"\"\"\n    try:\n        concierge = BusinessOperationsConcierge(request.user_id)\n        result = await concierge.process_request(request.message)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"service\": \"business-ops-agent\"}\n\nimport sys\n!{sys.executable} -m pip install nest_asyncio -q\n\nimport nest_asyncio\nnest_asyncio.apply()  # This allows uvicorn to run in notebook\n\nimport uvicorn\nimport asyncio\n\n# Check if we're in a notebook\ndef is_notebook():\n    try:\n        from IPython import get_ipython\n        return get_ipython() is not None\n    except:\n        return False\n\nif is_notebook():\n    print(\"ðŸ““ Running in Jupyter notebook mode...\")\n    \n    # Method 1: Run server in background thread\n    import threading\n    \n    def run_server():\n        config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n        server = uvicorn.Server(config)\n        asyncio.run(server.serve())\n    \n    # Start server\n    server_thread = threading.Thread(target=run_server, daemon=True)\n    server_thread.start()\n    \n    print(\"ðŸš€ Server started in background thread\")\n    print(\"ðŸ“¡ API available at: http://localhost:8000\")\n    print(\"ðŸ“š Docs at: http://localhost:8000/docs\")\n    print(\"\\nðŸ›‘ To stop: Kernel â†’ Interrupt\")\n    \nelse:\n    # Normal execution outside notebook\n    print(\"ðŸ’» Running in standard Python mode...\")\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:48:14.252273Z","iopub.execute_input":"2025-12-01T17:48:14.252586Z","iopub.status.idle":"2025-12-01T17:48:17.979321Z","shell.execute_reply.started":"2025-12-01T17:48:14.252562Z","shell.execute_reply":"2025-12-01T17:48:17.976970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. Orchestrator Agent (agents/orchestrator.py)","metadata":{}},{"cell_type":"code","source":"\"\"\"\nOrchestrator Agent - Demonstrates A2A Protocol and agent coordination\n\"\"\"\n\nfrom typing import List, Dict, Any\nfrom abc import ABC, abstractmethod\nimport json\n\nclass OrchestratorAgent:\n    \"\"\"Main orchestrator implementing A2A protocol patterns\"\"\"\n    \n    def __init__(self, llm, tools, support_agent, workflow_agent, data_agent, memory_bank):\n        self.llm = llm\n        self.tools = tools\n        self.support_agent = support_agent\n        self.workflow_agent = workflow_agent\n        self.data_agent = data_agent\n        self.memory_bank = memory_bank\n        self.conversation_history = []\n        \n    async def use_tools(self, query: str, tool_types: List[str] = None) -> str:\n        \"\"\"Use available tools based on query\"\"\"\n        \n        # Filter tools by type if specified\n        available_tools = self.tools\n        if tool_types:\n            available_tools = [t for t in self.tools \n                             if hasattr(t, 'tool_type') and t.tool_type in tool_types]\n        \n        # Create prompt for tool selection\n        tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}\" \n                                      for t in available_tools])\n        \n        prompt = f\"\"\"\n        You have access to these tools:\n        {tool_descriptions}\n        \n        User query: {query}\n        \n        Choose the most appropriate tool and provide the arguments as JSON.\n        Return format: {{\"tool\": \"tool_name\", \"args\": {{\"arg1\": \"value1\"}}}}\n        \"\"\"\n        \n        # Get tool selection from LLM\n        response = await self.llm.ainvoke(prompt)\n        \n        try:\n            tool_call = json.loads(response.content)\n            tool_name = tool_call[\"tool\"]\n            args = tool_call.get(\"args\", {})\n            \n            # Find and execute the tool\n            for tool in available_tools:\n                if tool.name == tool_name:\n                    result = tool.run(**args)\n                    \n                    # Log the tool execution\n                    self.conversation_history.append({\n                        \"type\": \"tool_call\",\n                        \"tool\": tool_name,\n                        \"args\": args,\n                        \"result\": str(result)[:200]  # Truncate long results\n                    })\n                    \n                    return result\n                    \n            return f\"Tool {tool_name} not found\"\n            \n        except json.JSONDecodeError:\n            return f\"Could not parse tool selection: {response.content}\"\n    \n    async def coordinate_agents(self, task: str) -> Dict[str, Any]:\n        \"\"\"Coordinate between multiple agents (A2A Protocol)\"\"\"\n        \n        # Analyze task complexity\n        analysis_prompt = f\"\"\"\n        Analyze this task and determine which agents should handle it:\n        Task: {task}\n        \n        Available agents:\n        1. Support Specialist: For questions and information\n        2. Workflow Agent: For process execution\n        3. Data Agent: For analysis and reporting\n        \n        Return JSON: {{\"primary_agent\": \"agent_name\", \"supporting_agents\": [\"agent1\", \"agent2\"]}}\n        \"\"\"\n        \n        analysis = await self.llm.ainvoke(analysis_prompt)\n        \n        try:\n            plan = json.loads(analysis.content)\n            primary = plan[\"primary_agent\"]\n            supporting = plan.get(\"supporting_agents\", [])\n            \n            results = {\"primary\": None, \"supporting\": {}}\n            \n            # Execute primary agent\n            if primary == \"support\":\n                results[\"primary\"] = await self.support_agent.answer_question(task)\n            elif primary == \"workflow\":\n                results[\"primary\"] = await self.workflow_agent.execute_workflow(task)\n            elif primary == \"data\":\n                results[\"primary\"] = await self.data_agent.analyze_trends(task)\n            \n            # Execute supporting agents in parallel (simulated)\n            for agent_name in supporting:\n                if agent_name == \"data\" and \"data\" not in [primary] + supporting:\n                    results[\"supporting\"][\"data\"] = await self.data_agent.generate_report(task)\n            \n            return results\n            \n        except Exception as e:\n            return {\"error\": str(e)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:34:24.008173Z","iopub.execute_input":"2025-12-01T17:34:24.008469Z","iopub.status.idle":"2025-12-01T17:34:24.021881Z","shell.execute_reply.started":"2025-12-01T17:34:24.008447Z","shell.execute_reply":"2025-12-01T17:34:24.020989Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. Custom Tools (tools/hr_tools.py)","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCustom HR Tools - Demonstrates custom tools and OpenAPI integration\n\"\"\"\n\nfrom typing import Optional, Dict, Any\nfrom datetime import datetime\nimport requests\n\nclass HRToolkit:\n    \"\"\"Collection of HR-related tools\"\"\"\n    \n    def get_tools(self):\n        return [\n            LeaveBalanceTool(),\n            PolicyLookupTool(),\n            EmployeeDirectoryTool(),\n            BenefitsEnrollmentTool()\n        ]\n\nclass LeaveBalanceTool:\n    \"\"\"Custom tool for checking leave balance\"\"\"\n    \n    name = \"check_leave_balance\"\n    description = \"Check an employee's remaining leave balance\"\n    tool_type = \"hr_tools\"\n    \n    def __init__(self):\n        # Simulated database\n        self.leave_data = {\n            \"EMP001\": {\"vacation\": 15, \"sick\": 10, \"personal\": 5},\n            \"EMP002\": {\"vacation\": 20, \"sick\": 8, \"personal\": 3}\n        }\n    \n    def run(self, employee_id: str, leave_type: Optional[str] = None) -> str:\n        \"\"\"Execute the tool\"\"\"\n        if employee_id not in self.leave_data:\n            return f\"Employee {employee_id} not found\"\n        \n        if leave_type:\n            if leave_type in self.leave_data[employee_id]:\n                balance = self.leave_data[employee_id][leave_type]\n                return f\"Employee {employee_id} has {balance} days of {leave_type} leave remaining\"\n            else:\n                return f\"Leave type {leave_type} not found\"\n        \n        # Return all balances\n        balances = self.leave_data[employee_id]\n        return f\"Leave balances for {employee_id}: {balances}\"\n\nclass PolicyLookupTool:\n    \"\"\"Tool to look up HR policies\"\"\"\n    \n    name = \"lookup_policy\"\n    description = \"Look up HR policies by topic\"\n    tool_type = \"hr_tools\"\n    \n    def __init__(self):\n        self.policies = {\n            \"remote_work\": \"Employees may work remotely up to 3 days per week with manager approval.\",\n            \"leave_request\": \"Submit leave requests at least 2 weeks in advance via the HR portal.\",\n            \"expenses\": \"Expense reports must be submitted within 30 days with receipts.\"\n        }\n    \n    def run(self, policy_topic: str) -> str:\n        return self.policies.get(\n            policy_topic.lower(),\n            f\"No policy found for topic: {policy_topic}\"\n        )\n\nclass EmployeeDirectoryTool:\n    \"\"\"OpenAPI tool integration example\"\"\"\n    \n    name = \"employee_directory\"\n    description = \"Look up employee information\"\n    tool_type = \"hr_tools\"\n    \n    def __init__(self):\n        self.api_url = \"https://api.example-hr.com/v1/employees\"\n        # In real implementation, you'd have proper auth headers\n    \n    def run(self, employee_id: Optional[str] = None, \n            department: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Simulated OpenAPI call\"\"\"\n        # Simulated API response\n        return {\n            \"employees\": [\n                {\"id\": \"EMP001\", \"name\": \"John Doe\", \"department\": \"Engineering\"},\n                {\"id\": \"EMP002\", \"name\": \"Jane Smith\", \"department\": \"Marketing\"}\n            ]\n        }\n\nclass BenefitsEnrollmentTool:\n    \"\"\"Tool for benefits enrollment workflow\"\"\"\n    \n    name = \"enroll_benefits\"\n    description = \"Enroll employee in benefits program\"\n    tool_type = \"hr_tools\"\n    \n    def run(self, employee_id: str, benefit_type: str, \n            coverage_level: str = \"standard\") -> str:\n        # Simulate enrollment process\n        return f\"Enrolled employee {employee_id} in {benefit_type} ({coverage_level} coverage). Confirmation: BEN{datetime.now().strftime('%Y%m%d%H%M%S')}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:35:07.693755Z","iopub.execute_input":"2025-12-01T17:35:07.694078Z","iopub.status.idle":"2025-12-01T17:35:07.705670Z","shell.execute_reply.started":"2025-12-01T17:35:07.694054Z","shell.execute_reply":"2025-12-01T17:35:07.704786Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4. Memory Management (memory/memory_bank.py)","metadata":{}},{"cell_type":"code","source":"\"\"\"\nMemory Bank - Demonstrates long-term memory and context compaction\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional\nfrom datetime import datetime, timedelta\nimport json\nfrom collections import defaultdict\n\nclass MemoryBank:\n    \"\"\"Long-term memory storage with context compaction\"\"\"\n    \n    def __init__(self, max_entries_per_user: int = 100):\n        self.memory_store = defaultdict(list)\n        self.max_entries = max_entries_per_user\n        \n    def store(self, user_id: str, key: str, value: Any, \n              metadata: Optional[Dict] = None) -> str:\n        \"\"\"Store information in long-term memory\"\"\"\n        \n        entry = {\n            \"id\": f\"{user_id}_{key}_{datetime.now().timestamp()}\",\n            \"key\": key,\n            \"value\": value,\n            \"timestamp\": datetime.now().isoformat(),\n            \"metadata\": metadata or {},\n            \"access_count\": 0\n        }\n        \n        # Add to user's memory\n        self.memory_store[user_id].append(entry)\n        \n        # Apply context compaction if needed\n        if len(self.memory_store[user_id]) > self.max_entries:\n            self._compact_context(user_id)\n        \n        return entry[\"id\"]\n    \n    def recall(self, user_id: str, key: Optional[str] = None, \n               limit: int = 5) -> List[Dict]:\n        \"\"\"Recall information from memory\"\"\"\n        \n        if user_id not in self.memory_store:\n            return []\n        \n        memories = self.memory_store[user_id]\n        \n        # Filter by key if specified\n        if key:\n            relevant = [m for m in memories if key in m[\"key\"]]\n        else:\n            relevant = memories\n        \n        # Sort by recency and access count\n        relevant.sort(key=lambda x: (\n            datetime.fromisoformat(x[\"timestamp\"]), \n            x[\"access_count\"]\n        ), reverse=True)\n        \n        # Update access count\n        for memory in relevant[:limit]:\n            memory[\"access_count\"] += 1\n        \n        return relevant[:limit]\n    \n    def _compact_context(self, user_id: str):\n        \"\"\"Context compaction: remove least accessed memories\"\"\"\n        memories = self.memory_store[user_id]\n        \n        # Sort by access count and recency\n        memories.sort(key=lambda x: (x[\"access_count\"], \n                                    datetime.fromisoformat(x[\"timestamp\"])))\n        \n        # Keep only the most recent/accessed memories\n        self.memory_store[user_id] = memories[-self.max_entries//2:]\n    \n    def get_user_patterns(self, user_id: str) -> Dict[str, Any]:\n        \"\"\"Analyze patterns in user interactions\"\"\"\n        memories = self.memory_store.get(user_id, [])\n        \n        if not memories:\n            return {}\n        \n        # Analyze frequencies\n        key_counts = defaultdict(int)\n        for memory in memories:\n            key_counts[memory[\"key\"]] += 1\n        \n        # Find most common topics\n        common_topics = sorted(key_counts.items(), \n                             key=lambda x: x[1], \n                             reverse=True)[:3]\n        \n        return {\n            \"total_memories\": len(memories),\n            \"common_topics\": dict(common_topics),\n            \"last_accessed\": memories[-1][\"timestamp\"] if memories else None\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:36:20.316227Z","iopub.execute_input":"2025-12-01T17:36:20.316520Z","iopub.status.idle":"2025-12-01T17:36:20.328556Z","shell.execute_reply.started":"2025-12-01T17:36:20.316495Z","shell.execute_reply":"2025-12-01T17:36:20.327594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. Evaluation Suite (evaluation/test_suite.py)","metadata":{}},{"cell_type":"code","source":"\"\"\"\nAgent Evaluation - Demonstrates systematic agent testing\n\"\"\"\n\nimport asyncio\nfrom typing import List, Dict, Tuple\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nclass AgentEvaluator:\n    \"\"\"Evaluate agent performance\"\"\"\n    \n    def __init__(self, agent):\n        self.agent = agent\n        self.test_cases = self._load_test_cases()\n        \n    def _load_test_cases(self) -> List[Dict]:\n        \"\"\"Load test cases for evaluation\"\"\"\n        return [\n            {\n                \"input\": \"What's my vacation balance?\",\n                \"expected_intent\": \"hr_inquiry\",\n                \"expected_tool\": \"check_leave_balance\"\n            },\n            {\n                \"input\": \"My laptop won't turn on\",\n                \"expected_intent\": \"it_support\",\n                \"expected_tool\": \"create_ticket\"\n            },\n            {\n                \"input\": \"Show me last month's support metrics\",\n                \"expected_intent\": \"data_analysis\",\n                \"expected_tool\": \"generate_report\"\n            },\n            {\n                \"input\": \"How do I submit an expense report?\",\n                \"expected_intent\": \"workflow\",\n                \"expected_tool\": \"lookup_policy\"\n            }\n        ]\n    \n    async def evaluate_intent_classification(self) -> Dict[str, float]:\n        \"\"\"Evaluate intent classification accuracy\"\"\"\n        predictions = []\n        true_labels = []\n        \n        for test_case in self.test_cases:\n            # Get agent's intent classification\n            result = await self.agent.process_request(test_case[\"input\"])\n            predicted_intent = result.get(\"intent\", \"unknown\")\n            \n            predictions.append(predicted_intent)\n            true_labels.append(test_case[\"expected_intent\"])\n        \n        # Calculate metrics\n        accuracy = accuracy_score(true_labels, predictions)\n        \n        # Get unique intents for multi-class metrics\n        unique_intents = list(set(true_labels + predictions))\n        \n        precision = precision_score(true_labels, predictions, \n                                  labels=unique_intents, average='weighted', zero_division=0)\n        recall = recall_score(true_labels, predictions,\n                            labels=unique_intents, average='weighted', zero_division=0)\n        \n        return {\n            \"accuracy\": accuracy,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"total_tests\": len(self.test_cases),\n            \"detailed_results\": list(zip(true_labels, predictions))\n        }\n    \n    async def evaluate_tool_selection(self) -> Dict[str, Any]:\n        \"\"\"Evaluate if correct tools are selected\"\"\"\n        correct_selections = 0\n        details = []\n        \n        for test_case in self.test_cases:\n            # Simulate tool selection (in real scenario, log tool calls)\n            result = await self.agent.process_request(test_case[\"input\"])\n            \n            # Check if expected tool was in the response\n            expected_tool = test_case[\"expected_tool\"]\n            response_text = str(result.get(\"response\", \"\")).lower()\n            \n            # Simple check - in production, you'd parse actual tool calls\n            if expected_tool in response_text:\n                correct_selections += 1\n                details.append({\"test\": test_case[\"input\"], \"correct\": True})\n            else:\n                details.append({\"test\": test_case[\"input\"], \"correct\": False})\n        \n        accuracy = correct_selections / len(self.test_cases)\n        \n        return {\n            \"tool_selection_accuracy\": accuracy,\n            \"correct_selections\": correct_selections,\n            \"total_tests\": len(self.test_cases),\n            \"details\": details\n        }\n    \n    async def run_complete_evaluation(self) -> Dict[str, Any]:\n        \"\"\"Run all evaluations\"\"\"\n        print(\"Starting agent evaluation...\")\n        \n        intent_results = await self.evaluate_intent_classification()\n        tool_results = await self.evaluate_tool_selection()\n        \n        # Calculate overall score\n        overall_score = (\n            intent_results[\"accuracy\"] * 0.6 +\n            tool_results[\"tool_selection_accuracy\"] * 0.4\n        )\n        \n        return {\n            \"overall_score\": overall_score,\n            \"intent_classification\": intent_results,\n            \"tool_selection\": tool_results,\n            \"passing_threshold\": 0.7,\n            \"passed\": overall_score >= 0.7,\n            \"timestamp\": datetime.now().isoformat()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:37:06.089348Z","iopub.execute_input":"2025-12-01T17:37:06.089683Z","iopub.status.idle":"2025-12-01T17:37:09.663362Z","shell.execute_reply.started":"2025-12-01T17:37:06.089658Z","shell.execute_reply":"2025-12-01T17:37:09.662307Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6. Deployment Configuration (Dockerfile)","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CREATE DEPLOYMENT FILES\n# ============================================\nimport os\n\nprint(\"ðŸ“¦ Creating deployment configuration...\")\n\n# 1. Create Dockerfile\ndockerfile = \"\"\"# Business Operations Concierge Agent\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application\nCOPY . .\n\n# Expose port\nEXPOSE 8000\n\n# Run application\nCMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\"\"\"\n\nwith open(\"Dockerfile\", \"w\") as f:\n    f.write(dockerfile)\nprint(\"âœ… Created: Dockerfile\")\n\n# 2. Create docker-compose.yml (optional)\ndocker_compose = \"\"\"version: '3.8'\n\nservices:\n  business-agent:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      - SERPAPI_API_KEY=${SERPAPI_API_KEY}\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"python\", \"-c\", \"import requests; requests.get('http://localhost:8000/health')\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\"\"\"\n\nwith open(\"docker-compose.yml\", \"w\") as f:\n    f.write(docker_compose)\nprint(\"âœ… Created: docker-compose.yml\")\n\n# 3. Create .dockerignore\ndockerignore = \"\"\"__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv\nvenv\n.venv\n.env\n.git\n.gitignore\nREADME.md\n*.ipynb\n.ipynb_checkpoints\n\"\"\"\n\nwith open(\".dockerignore\", \"w\") as f:\n    f.write(dockerignore)\nprint(\"âœ… Created: .dockerignore\")\n\n# 4. Create deployment instructions\ndeploy_readme = \"\"\"# Deployment Guide\n\n## Quick Start with Docker\n\n```bash\n# Build the image\ndocker build -t business-ops-agent .\n\n# Run the container\ndocker run -p 8000:8000 -e OPENAI_API_KEY=your_key business-ops-agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:50:25.553725Z","iopub.execute_input":"2025-12-01T17:50:25.554633Z","iopub.status.idle":"2025-12-01T17:50:25.562197Z","shell.execute_reply.started":"2025-12-01T17:50:25.554570Z","shell.execute_reply":"2025-12-01T17:50:25.561118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dockerfile for agent deployment\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    gcc \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Copy requirements\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Create non-root user\nRUN useradd -m -u 1000 agentuser && chown -R agentuser:agentuser /app\nUSER agentuser\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n    CMD python -c \"import requests; requests.get('http://localhost:8000/health')\"\n\n# Expose port\nEXPOSE 8000\n\n# Run the application\nCMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:37:46.901543Z","iopub.execute_input":"2025-12-01T17:37:46.902055Z","iopub.status.idle":"2025-12-01T17:37:46.909258Z","shell.execute_reply.started":"2025-12-01T17:37:46.902031Z","shell.execute_reply":"2025-12-01T17:37:46.908142Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7. Requirements File (requirements.txt)","metadata":{}},{"cell_type":"code","source":"# Core dependencies\nlangchain==0.1.0\nlangchain-openai==0.0.2\nlangchain-community==0.0.10\nopenai==1.3.0\n\n# Web framework\nfastapi==0.104.1\nuvicorn==0.24.0\npydantic==2.5.0\n\n# Tools and utilities\ngoogle-search-results==2.4.2\nrequests==2.31.0\npandas==2.1.3\nnumpy==1.24.3\n\n# Observability\nprometheus-client==0.19.0\nstructlog==23.2.0\n\n# Testing\npytest==7.4.3\npytest-asyncio==0.21.1","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:41:37.306320Z","iopub.execute_input":"2025-12-01T17:41:37.307033Z","iopub.status.idle":"2025-12-01T17:41:37.313344Z","shell.execute_reply.started":"2025-12-01T17:41:37.306996Z","shell.execute_reply":"2025-12-01T17:41:37.312242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8. Running and Testing","metadata":{}},{"cell_type":"code","source":"# 1. Install dependencies\npip install -r requirements.txt\n\n# 2. Run the agent system\npython app.py\n\n# 3. Test the API (in another terminal)\ncurl -X POST \"http://localhost:8000/process\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"user_id\": \"EMP001\", \"message\": \"What is my vacation balance?\"}'\n\n# 4. Run evaluation\npython -m evaluation.test_suite\n\n# 5. Build and deploy with Docker\ndocker build -t business-ops-agent .\ndocker run -p 8000:8000 --env OPENAI_API_KEY=your_key business-ops-agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:39:53.551551Z","iopub.execute_input":"2025-12-01T17:39:53.552453Z","iopub.status.idle":"2025-12-01T17:39:53.557904Z","shell.execute_reply.started":"2025-12-01T17:39:53.552426Z","shell.execute_reply":"2025-12-01T17:39:53.556802Z"}},"outputs":[],"execution_count":null}]}